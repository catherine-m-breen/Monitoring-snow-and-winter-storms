# -*- coding: utf-8 -*-
"""snowNet_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jMM52J9LDxdm3TtoN_y8hreSqHzqZOPI

## Load Packages
"""

# for data load
import os
import glob #for loading images from a directory

# for reading and processing images
from PIL import Image
import pandas as pd
import cv2

# for visualizations
import numpy as np
from IPython.display import clear_output
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

# for building and running deep learning model
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout 
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.losses import binary_crossentropy
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

"""## **Upload Snow Images (train data) and Mask Data (test data)**

We will upload train and test data from google drive. The data won't be sorted so we will have to sort it using sortMasks.

We will also write a short function called display() to visualize our data throughout the script.
"""

def display(display_list):
  plt.figure(figsize=(15, 15))

  title = ['Input Image', 'True Mask', 'Predicted Mask']

  for i in range(len(display_list)):
    plt.subplot(1, len(display_list), i+1)
    plt.title(title[i])
    plt.imshow(display_list[i])
    plt.axis('off')
  plt.show()

### optional ## just images in white flash / daylight 
# Find the average saturation of an image
def avg_saturation(rgb_image):
    # Convert image to HSV
    hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)

    # Add up all the pixel values in the V channel
    sum_brightness = np.sum(hsv[:,2,0])
    area = 600*1100.0  # pixels
    
    # find the avg
    avg = sum_brightness/area
    
    return avg

inputImages = []
inputImagesNames = []
for file in glob.glob("drive/My Drive/ImageSegmentation/InputImage/*"):
  if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg'):
    filename = file.split('/')[-1]
    image = cv2.imread(file)
    ## add a cropping step 
    image = image[30:-30,:] ## crop top and bottom

    ## optional ##
    saturation = avg_saturation(image)
    if saturation > 0.02:
    #####
    
      inputImages.append(image)
      inputImagesNames.append(filename)

maskedImages = []
maskedImagesNames = []
for file in glob.glob("drive/My Drive/ImageSegmentation/TrueMask/*"):
  if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg'):
    image = cv2.imread(file)
    image = image[30:-30,:]
    maskedImages.append(image)
    filename = file.split('_',1)[1]
    name = (filename.split('.')[0])
    ending = (filename.split('.')[1]).upper()
    filename = name + '.' + ending
    maskedImagesNames.append(filename)

## glob doesn't always work in the same order so we want to be sure that everything is in the same order, we will sort by name (ascending) and then make sure everything lines up 
def sortMasks(inputImages, inputImagesNames, maskedImages, maskedImagesNames):

  df1 = pd.DataFrame(inputImagesNames)
  df2 = pd.DataFrame(maskedImagesNames)

  sortedImages = []#[None] * len(df1) 
  sortedImagesNames = []#[None] * len(df1)
  sortedMasks = []#[None] * len(df1)
  sortedMasksNames = []#[None] * len(df1)
  for i in range(0, len(df1)):
    if sum(df2[0] == df1[0][i]) > 0:
     sortedImages.append(inputImages[i])
     sortedImagesNames.append(inputImagesNames[i])    
     index = (df2[df2[0] == df1[0][i]]).index[0]
     mask = maskedImages[index]
     name = maskedImagesNames[index]
     sortedMasks.append(mask) 
     sortedMasksNames.append(name) 
     # index = (df2[df2[0] == df1[0][i]]).index[0]
      #mask = maskedImages[index]
     # name = maskedImagesNames[index]
      #sortedMasks[i]= mask
      #sortedMasksNames[i] = name

  return sortedImages, sortedImagesNames, sortedMasks, sortedMasksNames

inputImages, inputImagesNames, maskedImages, maskedImagesNames = sortMasks(inputImages, inputImagesNames, maskedImages, maskedImagesNames)

names = pd.DataFrame({'inputImagesNames': inputImagesNames, 'maskedImagesNames': maskedImagesNames})
names[names['inputImagesNames'] != names['maskedImagesNames']]

len(inputImages), len(inputImagesNames), len(maskedImages), len(maskedImagesNames)

r = 20
display([inputImages[r], maskedImages[r]])

"""### Generic function to load images

We will resize the image and set to float32. In the loop we will separate the binary testing data into two separate binary images, which are technically just inverted masks of each other. Then, we will put them into one tensor using stack so that the tensor is 128 x 128 x 2 channels
"""

### could add cropping here because we dont need the top and bottom of the image 

def load_image(image, mask):
  input_image = tf.image.resize(image, (128, 128))
  input_mask = tf.image.resize(mask, (128, 128))
  input_image = tf.cast(input_image, tf.float32) / 255.0
  return input_image, input_mask

def Preprocessing(inputImages, maskedImages):
  x_data = []
  #y_data1 = []
  #y_data2 = []
  y_data = []
  for i in range(0, len(inputImages)):
    x, y = load_image(inputImages[i], maskedImages[i])
    y = y[:,:,0]//255
    y1 = tf.cast(y, dtype = tf.uint16)
    y2 = tf.bitwise.invert(y1)
    y2= y2[:,:]//65535 ## I don't know why it's doing that but it works if you divide it by 65535. We may need to convert back to float 32
    #(print(x.shape))
    t1 = y1 ### snow
    t2 = y2 ### no snow
    stack = tf.stack([y2, y1], 2) ## channel 0 = no snow; channel 2 = snow
    x_data.append(x)
    #y_data1.append(y1)
    #y_data2.append(y2)
    y_data.append(stack)
  return x_data, y_data

x_data, y_data = Preprocessing(inputImages, maskedImages)

"""Here is an example of how the dataset is two channels of inverted masks of each other.

## Visualize Mask Distribution
"""

pixelHist = []
for i in range(len(y_data)):
  image = y_data[i][:,:,1]
  height, width = image.shape
  image = image[10:(height-10),:]

  #bottom_half = round(height/2)
  #plt.imshow(image[(round(height/2)):height,:]) just bottom half 
    # errors include (trees, animal in image, etc)
  #cropped = image[(round(height/2)):(height-10),:]
  #width, height = cropped.shape
  white_pixel_fraction = (np.sum(image))/(width *height)
  pixelHist.append(white_pixel_fraction)

plt.hist(pixelHist, bins = 20)
plt.xlabel('Snow Pixel Fractions')
plt.ylabel('Number of images')
plt.title('Snow Fraction Distribution from True Masks')
plt.grid(False)#b=None)
plt.tight_layout()
plt.tick_params(axis='x', which='both', bottom=True, top=False)
plt.tick_params(axis='y', which='both', right=False, left=True)
plt.show()

"""## Split data for model """

X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=42)

train_images = {'image':X_train, 'segmentation_mask':y_train}
test_imags = {'image':X_test, 'segmentation_mask':y_test}

"""## Visualize Data"""

fig = plt.figure()
for i in range(0, len(train_images)):
  sample_image, sample_mask = train_images['image'][i], train_images['segmentation_mask'][i]
  display([sample_image, sample_mask[:,:,1]])

"""## Define the model
The model being used here is a modified [U-Net](https://arxiv.org/abs/1505.04597). A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features and reduce the number of trainable parameters, you will use a pretrained model - MobileNetV2 - as the encoder. For the decoder, you will use the upsample block, which is already implemented in the [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) example in the TensorFlow Examples repo. (Check out the [pix2pix: Image-to-image translation with a conditional GAN](../generative/pix2pix.ipynb) tutorial in a notebook.)

As mentioned, the encoder will be a pretrained MobileNetV2 model which is prepared and ready to use in `tf.keras.applications`. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process.
"""

def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True):
    """
    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning. 
    Dropout can be added for regularization to prevent overfitting. 
    The block returns the activation values for next layer along with a skip connection which will be used in the decoder
    """
    # Add 2 Conv Layers with relu activation and HeNormal initialization using TensorFlow 
    # Proper initialization prevents from the problem of exploding and vanishing gradients 
    # 'Same' padding will pad the input to conv layer such that the output has the same height and width (hence, is not reduced in size) 
    conv = Conv2D(n_filters, 
                  3,   # Kernel size   
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(inputs)
    conv = Conv2D(n_filters, 
                  3,   # Kernel size
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(conv)
    
    # Batch Normalization will normalize the output of the last layer based on the batch's mean and standard deviation
    conv = BatchNormalization()(conv, training=False)

    # In case of overfitting, dropout will regularize the loss and gradient computation to shrink the influence of weights on output
    if dropout_prob > 0:     
        conv = tf.keras.layers.Dropout(dropout_prob)(conv)

    # Pooling reduces the size of the image while keeping the number of channels same
    # Pooling has been kept as optional as the last encoder layer does not use pooling (hence, makes the encoder block flexible to use)
    # Below, Max pooling considers the maximum of the input slice for output computation and uses stride of 2 to traverse across input image
    if max_pooling:
        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    
    else:
        next_layer = conv

    # skip connection (without max pooling) will be input to the decoder layer to prevent information loss during transpose convolutions      
    skip_connection = conv
    
    return next_layer, skip_connection

def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32):
    """
    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,
    merges the result with skip layer results from encoder block
    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions
    The function returns the decoded layer output
    """
    # Start with a transpose convolution layer to first increase the size of the image
    up = Conv2DTranspose(
                 n_filters,
                 (3,3),    # Kernel size
                 strides=(2,2),
                 padding='same')(prev_layer_input)

    # Merge the skip connection from previous block to prevent information loss
    merge = concatenate([up, skip_layer_input], axis=3)
    
    # Add 2 Conv Layers with relu activation and HeNormal initialization for further processing
    # The parameters for the function are similar to encoder
    conv = Conv2D(n_filters, 
                 3,     # Kernel size
                 activation='relu',
                 padding='same',
                 kernel_initializer='HeNormal')(merge)
    conv = Conv2D(n_filters,
                 3,   # Kernel size
                 activation='relu',
                 padding='same',
                 kernel_initializer='HeNormal')(conv)
    return conv

#   """
 #  Combine both encoder and decoder blocks according to the U-Net research paper
 #  Return the model as output 
 #  """

def UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=2):

    # Input size represent the size of 1 image (the size used for pre-processing) 
    inputs = Input(input_size)
    
    # Encoder includes multiple convolutional mini blocks with different maxpooling, dropout and filter parameters
    # Observe that the filters are increasing as we go deeper into the network which will increasse the # channels of the image 
    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True)
    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True)
    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True)
    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True)
    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) 
    
    # Decoder includes multiple mini blocks with decreasing number of filters
    # Observe the skip connections from the encoder are given as input to the decoder
    # Recall the 2nd output of encoder block was skip connection, hence cblockn[1] is used
    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8)
    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4)
    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2)
    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters)

    # Complete the model with 1 3x3 convolution layer (Same as the prev Conv Layers)
    # Followed by a 1x1 Conv layer to get the image to the desired size. 
    # Observe the number of channels will be equal to number of output classes
    conv9 = Conv2D(n_filters,
                 2,
                 activation='relu',
                 padding='same',
                 kernel_initializer='he_normal')(ublock9)

    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)
    
    # Define the model
    model = tf.keras.Model(inputs=inputs, outputs=conv10)

    return model

# Call the helper function for defining the layers for the model, given the input image size
unet = UNetCompiled(input_size=(128,128,3), n_filters=32, n_classes=2)

# Check the summary to better interpret how the output dimensions change in each layer
unet.summary()

#tf.keras.utils.plot_model(unet, show_shapes=True)

"""## Train the model

Now, all that is left to do is to compile and train the model. 

Since this is a multiclass classification problem, use the `tf.keras.losses.CategoricalCrossentropy` loss function with the `from_logits` argument set to `True`, since the labels are scalar integers instead of vectors of scores for each pixel of every class. 

When running inference, the label assigned to the pixel is the channel with the highest value. This is what the `create_mask` function is doing.
"""

# There are multiple optimizers, loss functions and metrics that can be used to compile multi-class segmentation models
# Ideally, try different options to get the best accuracy
unet.compile(optimizer=tf.keras.optimizers.Adam(), 
             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

x_train = tf.convert_to_tensor(X_train) #tf.expand_dims(X_train, 0)
y_train = tf.convert_to_tensor(y_train)#tf.expand_dims(y_train, 3)
x_test =  tf.convert_to_tensor(X_test)#tf.expand_dims(X_test, 0)
y_test = tf.convert_to_tensor(y_test)#tf.expand_dims(y_test,3)

print(x_train.shape)
print(y_train.shape)

# Run the model in a mini-batch fashion and compute the progress for each epoch
model_history = unet.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test))

"""## Now we will add convert our lists to tensors, and add a dimension to the test data in the process. 

We have to add a dimension to the test data using .expand_dims() becaus the binary information isn't automatically included in the channel. 

We also need our tensors to match the shape of the model for inputs and outputs (None, X, Y, channel) and (none, X, Y, 1)
"""

x_train = tf.convert_to_tensor(X_train) #tf.expand_dims(X_train, 0)
y_train = tf.convert_to_tensor(y_train)#tf.expand_dims(y_train, 3)
x_test =  tf.convert_to_tensor(X_test)#tf.expand_dims(X_test, 0)
y_test = tf.convert_to_tensor(y_test)#tf.expand_dims(y_test,3)

print(x_train.shape)
print(y_train.shape)

"""## Predict model before training

Try out the model to check what it predicts before training.
"""

def show_predictions(image):
  image = tf.expand_dims(image, axis=0) 
  pred_mask = unet.predict(image)
  vis1 = pred_mask[0,:,:,0]
  pred_mask1 = tf.math.argmax(pred_mask, axis = -1)
  print(pred_mask1.shape)
  vis2 = pred_mask1[0,:,:]
  fig, (ax1, ax2) = plt.subplots(1,2)
  ax1.imshow(vis1)
  ax2.imshow(vis2)

show_predictions(x_train[0])

"""## Train Model"""

loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

plt.figure()
plt.plot(model_history.epoch, loss, 'r', label='Training loss')
plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss Value')
plt.ylim([0, 1])
plt.legend()
plt.show()

"""## Make predictions

Now, make some predictions. In the interest of saving time, the number of epochs was kept small, but you may set this higher to achieve more accurate results.
"""

def make_predictions(image):
  image = tf.expand_dims(image, axis=0) #x_train[0:1,:]
  pred_mask = unet.predict(image)
  #print(pred_mask.shape) ## probabilities

  pred_mask1 = tf.math.argmax(pred_mask, axis = -1)
  #print(pred_mask1.shape)
  #plt.imshow(pred_mask1[0,:,:]) ## final mask
  prediction = pred_mask1[0,:,:]
  return prediction

prediction = []
for i in range(0, len(x_train)):
  output = make_predictions(x_train[i])
  prediction.append(output)

k = 1
display([x_train[1], y_train[1][:,:,1], prediction[1]])

"""## Model Performance Evaluation
F1 score, accuracy and precision between true mask and predicted mask

Precision: the percentage of snow classifications predicted by our model that are also snow classifications in the true mask.
 precision = (True Positives / (True Positives + False Positives) 

Recall: the percentage of true snow classifications predicted by our model that are also true snow classifications in the compared dataset
  recall = (True Positives) / (True Positives + False Negatives) 

FScore: The harmonic mean of precision and recall. 
  FScore = 2 * (Precision X Recall) / (Precision + Recall) 


"""

p = tf.keras.metrics.Precision()
p.update_state([y_train[1][:,:,1]], [prediction[1]])
precision = p.result().numpy()
precision

m = tf.keras.metrics.Recall()
m.update_state([y_train[1][:,:,1]], [prediction[1]])
recall = m.result().numpy()

#Fscore 
Fscore = 2 * (precision * recall)/(precision + recall)

def modelEvaluation(trueMask, predictedMask):
  p = tf.keras.metrics.Precision()
  p.update_state([trueMask], [predictedMask])
  precision = p.result().numpy()
  m = tf.keras.metrics.Recall()
  m.update_state([trueMask], [predictedMask])
  recall = m.result().numpy()
  Fscore = 2 * (precision * recall)/(precision + recall)
  if recall == 0:
    Fscore = 0
  return  precision, recall, Fscore

modelEvaluation(trueMask = y_train[1][:,:,1], predictedMask = prediction[1])

precision, recall, Fscore = [], [], []
for i in range(0, len(x_train)):
  precision1, recall1, Fscore1 = modelEvaluation(trueMask = y_train[i][:,:,1], predictedMask = prediction[i])
  precision.append(precision1)
  recall.append(recall1)
  Fscore.append(Fscore1)

print(np.mean(precision))
print(np.mean(recall))
print(np.mean(Fscore))

## results = pd.DataFrame({'precision':precision, 'recall':recall, 'Fscore':Fscore})
results = pd.DataFrame({'precision':precision, 'recall':recall, 'Fscore':Fscore})
print(results)
snow_images = results[results['precision']!= 0.0]
np.mean(snow_images['Fscore'])

results[results['Fscore'] < 0.50]

## inspect 1 image
n = 33
print(modelEvaluation(trueMask = y_train[n][:,:,1], predictedMask = prediction[n]))
display([x_train[n], y_train[n][:,:,1], prediction[n]])

fig, axes = plt.subplots(len(x_train), 3, figsize=(9,len(x_train)*3))

for i in range(len(x_train)):
    ax1, ax2, ax3 = axes[i]
    ax1.imshow(x_train[i])
    ax1.axis('off') # for removing axis
    ax2.axis('off')
    ax3.axis('off')
    #ax1.set_title('Original Image')
    ax2.imshow(y_train[i][:,:,1])
    #ax2.set_title('True Mask')
    ax3.imshow(prediction[i])
    #ax3.set_title('Predicted Mask')

plt.subplots_adjust(hspace = 0, wspace = 0)
plt.show()

"""## White Pixel Fraction"""

image = prediction[1]
height, width = image.shape
print(image.shape)
bottom_half = round(height/2)

  #plt.imshow(image[(round(height/2)):height,:]) just bottom half 
    # errors include (trees, animal in image, etc)
cropped = image[(round(height/2)):(height-10),:] ## above 10 pixels of the bottom ribbon
plt.imshow(cropped)

width, height = cropped.shape
white_pixel_fraction = (np.sum(cropped))/(width *height)
white_pixel_fraction

"""# Predict on unseen data 


"""

## load in the Labeled Images 
path = 'drive/My Drive/LabeledImages/'
originalData = []
unseenData = []
filenames = []
for file in glob.glob(os.path.join(path + "*")):
  #print(file)
  if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg'):
    image = cv2.imread(file)
    input_image = tf.image.resize(image, (128, 128)) ## change this to preprocessing ## 
    input_image = tf.cast(input_image, tf.float32) / 255.0
    originalData.append(input_image)
    output = make_predictions(input_image)
    unseenData.append(output)
    
    ## get filename
    filename = file.split('/')[-1]
    filenames.append(filename)

path = 'drive/My Drive/LabeledImages/'
filenames = []
for file in glob.glob(os.path.join(path + "*")):
  #print(file)
  if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg'):
    image = cv2.imread(file)
    filename = file.split('/')[-1]
    filenames.append(filename)

f = 8000
display([originalData[f], unseenData[f]])

## count pixels
fractions = []
for i in range(0, len(unseenData)):
  image = unseenData[i]
  height, width = image.shape
  #print(image.shape)
  bottom_half = round(height/2)
  #plt.imshow(image[(round(height/2)):height,:]) just bottom half 
    # errors include (trees, animal in image, etc)
  cropped = image[(round(height/2)):(height-10),:]
  width, height = cropped.shape
  white_pixel_fraction = (np.sum(cropped))/(width *height)
  fractions.append(white_pixel_fraction)

df = pd.DataFrame({"filename" : filenames, "whitePixelIndexAI" : fractions})
df.to_csv("drive/My Drive/AI_fractions_unet.csv", index=False)

df.head()

"""To do:

weight the loss function
add more data
build in assumptions about snow?

## Optional: Imbalanced classes and class weights

Semantic segmentation datasets can be highly imbalanced meaning that particular class pixels can be present more inside images than that of other classes. Since segmentation problems can be treated as per-pixel classification problems, you can deal with the imbalance problem by weighing the loss function to account for this. It's a simple and elegant way to deal with this problem. Refer to the [Classification on imbalanced data](../structured_data/imbalanced_data.ipynb) tutorial to learn more.

To [avoid ambiguity](https://github.com/keras-team/keras/issues/3653#issuecomment-243939748), `Model.fit` does not support the `class_weight` argument for inputs with 3+ dimensions.
"""

try:
  model_history1 = unet.fit(x_train, y_train, epochs=20,
                            steps_per_epoch=2,
                            class_weight = {0:2.0, 1:2.0, 2:1.0})
                            
             ##     model_history = unet.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test))'
  assert False
except Exception as e:
  print(f"Expected {type(e).__name__}: {e}")

"""So, in this case you need to implement the weighting yourself. You'll do this using sample weights: In addition to `(data, label)` pairs, `Model.fit` also accepts `(data, label, sample_weight)` triples.

`Model.fit` propagates the `sample_weight` to the losses and metrics, which also accept a `sample_weight` argument. The sample weight is multiplied by the sample's value before the reduction step. For example:
"""

label = [0,0]
prediction = [[-3., 0], [-3, 0]]  
sample_weight = [1, 10] 

loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True,
                                               reduction=tf.losses.Reduction.NONE) ## i think I need to delete the word Sparse but then it doesn't like it 
loss(label, prediction, sample_weight).numpy()

"""So to make sample weights for this tutorial you need a function that takes a `(data, label)` pair and returns a `(data, label, sample_weight)` triple. Where the `sample_weight` is a 1-channel image containing the class weight for each pixel. 

The simplest possible implementation is to use the label as an index into a `class_weight` list:
"""

def add_sample_weights(image, label):
  # The weights for each class, with the constraint that:
  #     sum(class_weights) == 1.0
  class_weights = tf.constant([20.0, 50.0, 1.0]) ## was 2.0, 2.0, 1.0
  class_weights = class_weights/tf.reduce_sum(class_weights)

  # Create an image of `sample_weights` by using the label at each pixel as an 
  # index into the `class weights` .
  sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))

  return image, label, sample_weights

"""The resulting dataset elements contain 3 images each:"""

weightedData = add_sample_weights(x_train, y_train)

print(y_train.shape)
print(weightedData[2].shape)

## help here!

display([ y_train[40,:,:,1], test[0][40,:,:,1] ])

## original mask and weighted masked

"""Now you can train a model on this weighted dataset:"""

weighted_model = unet
weighted_model.compile(
    optimizer='adam',
    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), ## had to drop Sparse to get it to work 
    metrics=['accuracy'])

weighted_model.fit(x_train, test[0], batch_size=32, epochs=20, validation_data=(x_test, y_test))

"""## Next steps
Now that you have an understanding of what image segmentation is and how it works, you can try this tutorial out with different intermediate layer outputs, or even different pretrained models. You may also challenge yourself by trying out the [Carvana](https://www.kaggle.com/c/carvana-image-masking-challenge/overview) image masking challenge hosted on Kaggle.

You may also want to see the [Tensorflow Object Detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md) for another model you can retrain on your own data. Pretrained models are available on [TensorFlow Hub](https://www.tensorflow.org/hub/tutorials/tf2_object_detection#optional)
"""
